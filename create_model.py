# -*- coding: utf-8 -*-
"""Untitled187.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZDa5luTpyfQhjlXEhwqgdwtqsmo2INZ8
"""

import numpy as np
import pandas as pd
from IPython.display import clear_output
from matplotlib import pyplot as plt
import tensorflow as tf
tf.random.set_seed(123)

# Load dataset.
dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')
y_train = dftrain.pop('survived')
y_eval = dfeval.pop('survived')

dftrain=dftrain.drop(columns=['class'])
dfeval=dfeval.drop(columns=['class'])

CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'deck',
                       'embark_town', 'alone']
NUMERIC_COLUMNS = ['age', 'fare']

def one_hot_cat_column(feature_name, vocab):
  return tf.feature_column.indicator_column(
      tf.feature_column.categorical_column_with_vocabulary_list(feature_name,
                                                 vocab))
feature_columns = []
for feature_name in CATEGORICAL_COLUMNS:
  # Need to one-hot encode categorical features.
  vocabulary = dftrain[feature_name].unique()
  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))

for feature_name in NUMERIC_COLUMNS:
  feature_columns.append(tf.feature_column.numeric_column(feature_name,
                                           dtype=tf.float32))
  

NUM_EXAMPLES = len(y_train)

def make_input_fn(X, y, n_epochs=None, shuffle=True):
  def input_fn():
    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))
    if shuffle:
      dataset = dataset.shuffle(NUM_EXAMPLES)
    # For training, cycle thru dataset as many times as need (n_epochs=None).
    dataset = dataset.repeat(n_epochs)
    # In memory training doesn't use batching.
    dataset = dataset.batch(NUM_EXAMPLES)
    return dataset
  return input_fn

# Training and evaluation input functions.
train_input_fn = make_input_fn(dftrain, y_train)
eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)


n_batches = 1
est = tf.estimator.BoostedTreesClassifier(feature_columns,
                                          n_batches_per_layer=n_batches)

# The model will stop training once the specified number of trees is built, not
# based on the number of steps.
est.train(train_input_fn, max_steps=100)




features_raw_placeholder = {
    'sex': tf.keras.backend.placeholder(shape=(1,), dtype=tf.string, name='input_age'),
    'n_siblings_spouses': tf.keras.backend.placeholder(shape=(1,), dtype=tf.int64, name='input_fare'),
       'parch': tf.keras.backend.placeholder(shape=(1,), dtype=tf.int64, name='input_age'),
       'deck': tf.keras.backend.placeholder(shape=(1,), dtype=tf.string, name='input_age'),
    'embark_town': tf.keras.backend.placeholder(shape=(1,), dtype=tf.string, name='input_fare'),
        'alone': tf.keras.backend.placeholder(shape=(1,), dtype=tf.string, name='input_fare'),
       'age': tf.keras.backend.placeholder(shape=(1,), dtype=tf.float32, name='input_age'),
    'fare': tf.keras.backend.placeholder(shape=(1,), dtype=tf.float32, name='input_fare')
}

serving_raw_input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn(features=features_raw_placeholder)

export_path = est.export_saved_model('saved_model/my_model', serving_raw_input_fn)